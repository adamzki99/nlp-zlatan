{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamzki99/nlp-zlatan/blob/feature%2Fdoc2vec_approach/nlp_zlatan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive"
      ],
      "metadata": {
        "id": "1LcgYJ860QY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJSvTgIasmNY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nlp-datasets/wizard_of_wikipedia"
      ],
      "metadata": {
        "id": "asHbxFDYtSbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the dataset"
      ],
      "metadata": {
        "id": "aaw3vDKc0NyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('data.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    data = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(data))"
      ],
      "metadata": {
        "id": "zNAyB_-G0-hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration\n"
      ],
      "metadata": {
        "id": "-YtskZfY1xax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "s9iCsQnG12Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "id": "LqSiuJuT3yhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].keys()"
      ],
      "metadata": {
        "id": "FItaavoM14Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]['chosen_topic_passage']"
      ],
      "metadata": {
        "id": "Rx8-W6g716_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].keys()"
      ],
      "metadata": {
        "id": "DUB4GiOa18Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0]['persona'])\n",
        "print(data[0]['chosen_topic'])"
      ],
      "metadata": {
        "id": "W8FkeplX19Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary keys of Wizard"
      ],
      "metadata": {
        "id": "_PhHMPhgxACA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]['dialog'][0].keys()"
      ],
      "metadata": {
        "id": "0sdaj_Z21-dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary keys of Apprentice"
      ],
      "metadata": {
        "id": "GOv5VWLBxBC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]['dialog'][1].keys()"
      ],
      "metadata": {
        "id": "xFLYL0kZxC0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(i, \":\", data[0]['dialog'][i]['text'])"
      ],
      "metadata": {
        "id": "vyKUxYnW1_sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(i, \":\", data[0]['dialog'][i]['retrieved_topics'])"
      ],
      "metadata": {
        "id": "qGAE9W2v2Bgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(i, \":\", data[0]['dialog'][i]['retrieved_passages'])"
      ],
      "metadata": {
        "id": "J9Kqu9tX2Ck3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring uniqe types\n",
        "\n",
        "Exploring how many uniqe \"chosen_topic\"s, \"persona\"s and \"wizard_eval\"s there are in the dataset"
      ],
      "metadata": {
        "id": "eehAX-lw3-N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = []\n",
        "personas = []\n",
        "wizardEvals = []\n",
        "\n",
        "for entry in data:\n",
        "\n",
        "  topics.append(entry['chosen_topic'])\n",
        "  personas.append(entry['persona'])\n",
        "  wizardEvals.append(entry['wizard_eval'])\n",
        "\n",
        "# Making the list containing only uniqe items\n",
        "topics = list(set(topics))\n",
        "personas = list(set(personas))\n",
        "wizardEvals = list(set(wizardEvals))\n",
        "\n",
        "print(\"topic:\", len(topics), \"persona:\", len(personas), \"wizard_eval:\", len(wizardEvals))"
      ],
      "metadata": {
        "id": "fwRuecUM4w2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are there more than 5 different \"wizard_eval\"s? The paper only mentions a rating from 1-5. What are the other 2?"
      ],
      "metadata": {
        "id": "yXTQPnbQxQl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in wizardEvals:\n",
        "  print(wizardEvals[entry] )\n",
        "#what's up with -1 and 0? In paper only ratings from 1 to 5 are mentioned"
      ],
      "metadata": {
        "id": "A2XOiKF2xUYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How often does each rating occur in \"wizard_eval\"s? Visualize all the different instances in a histogram"
      ],
      "metadata": {
        "id": "kouaxYL5xXDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "wEval = []\n",
        "\n",
        "for entry in data:\n",
        "    wEval.append(entry['wizard_eval'])\n",
        "\n",
        "plt.hist(wEval, bins=2*len(set(wEval))) #the number of bins can probably be improved to look nicer\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UMp8N4p1xcNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a topic?\n",
        "\n",
        "topics[:10]"
      ],
      "metadata": {
        "id": "W7wKG6W26xXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a persona?\n",
        "\n",
        "personas[:10]"
      ],
      "metadata": {
        "id": "lOF94u5a6mVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open question 1\n",
        "\n",
        "Maybe there is some relation between topics and personas that we might be able to cluster in order to get som further insight?"
      ],
      "metadata": {
        "id": "D0N77y0H7CFi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XiVhAovT7MmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trying to cluster (Farid)"
      ],
      "metadata": {
        "id": "MucRY9lP7QON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data preprocessing"
      ],
      "metadata": {
        "id": "b5Utms4z7Viq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data before clustering "
      ],
      "metadata": {
        "id": "xal8rNbH7Zvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining chosen_topic and chosen_topic_passage (basically the Wiki article) to try to cluster them afterwards "
      ],
      "metadata": {
        "id": "NqdT4-Xm7z4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [f\"{sample['chosen_topic']}\\n\\n\" + \"\\n\".join([f\"{passage}\" for passage in sample['chosen_topic_passage']]) for sample in data]"
      ],
      "metadata": {
        "id": "qWyfOAoD7ifC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(topics[10]) #The 'chosen_topic' is repepated at the beginning of the article anyway, so no need in repeating it tbh"
      ],
      "metadata": {
        "id": "nInRdTdf_cZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Vectorization of topics using TFIDF"
      ],
      "metadata": {
        "id": "k-uQTfALP9sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, stop_words='english')"
      ],
      "metadata": {
        "id": "H5ep44tbP9H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the vectorizer to the data"
      ],
      "metadata": {
        "id": "7sdowEmuQawU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.fit(topics)"
      ],
      "metadata": {
        "id": "HhqHynK7QSLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Size of Vocabulary"
      ],
      "metadata": {
        "id": "zLEcBP5zQjkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(f\"Length of vocabulary: {len(vocab)}\")"
      ],
      "metadata": {
        "id": "bz-csGyyQlCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random sampling from Vocabulary"
      ],
      "metadata": {
        "id": "OkVHi3H7Qyr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "sorted(random.sample(vocab.tolist(),20))"
      ],
      "metadata": {
        "id": "bIlclgl5Q1rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization of topics"
      ],
      "metadata": {
        "id": "6FwBphFcRV8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_topics = vectorizer.transform(topics)"
      ],
      "metadata": {
        "id": "YOAMyKaZRtZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF values of first topic"
      ],
      "metadata": {
        "id": "InVOm9VNSEep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([(vocab[j], vector_topics[0, j]) for j in vector_topics[0].nonzero()[1]], key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "2OeEoUUhR4Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Minibatch k-means"
      ],
      "metadata": {
        "id": "tXt14CENWFb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans"
      ],
      "metadata": {
        "id": "niArSuUWWtZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Elbow method to find number of clusters k"
      ],
      "metadata": {
        "id": "ve3UkM3jWRqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the performance evaluation measure values across the range of k values -> Decrease k to around 50 to run faster"
      ],
      "metadata": {
        "id": "iSuqAL2IYDhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance = [MiniBatchKMeans(n_clusters=k, batch_size=500, random_state=2307).fit(vector_topics).inertia_ for k in range(1,100)]"
      ],
      "metadata": {
        "id": "hkwQ4bIkWWO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use some standard code to plot the performance measure against the value k"
      ],
      "metadata": {
        "id": "Zc9Ykd18X_Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(performance)\n",
        "plt.ylabel('Within-cluster sum-of-squares')\n",
        "plt.xlabel('k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UaSy9Ksz3qRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to tutorial 4: \"In theory it should always increase since the more cluster centroids there are, the more flexibility the model has for describing datapoints (assigning them to clusters)\"\n",
        "\n",
        "So something is probably wrong"
      ],
      "metadata": {
        "id": "RbstLeGmXZrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iz1_MQqbknrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uJJfW9ixMoA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Doc2Vec Approach (Farid)"
      ],
      "metadata": {
        "id": "ZhVbjwWvMpMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import necessary tools"
      ],
      "metadata": {
        "id": "GoourtoSgry7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "id": "_XclCLhLgrZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "Mr5bVUgWgxcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install blas to reduce computation time (this obvs doesn't work -> find out how to fix)"
      ],
      "metadata": {
        "id": "jXE3cxWsg3bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.linalg\n",
        "from scipy.linalg import blas"
      ],
      "metadata": {
        "id": "I9D_bxqGg5_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pyblas"
      ],
      "metadata": {
        "id": "BiuwahfUg8eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "VlrUB_yYMt1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('data.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    data = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(data))"
      ],
      "metadata": {
        "id": "DQ_tXD52aBeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quick look at the Data"
      ],
      "metadata": {
        "id": "MFbl-l79aOen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataframe is never used, but it is useful for looking at the dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "1DxdlaJhaNu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing the Data"
      ],
      "metadata": {
        "id": "QasbA5Bkbd2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first have to decide which Data we want to use to train the model aka what goal are we trying to achieve.\n",
        "As we want to retrieve the correct passage for each turn we should probably train the model on the passages given and then try to retrieve the chosen passage given a sentence from the dialogue"
      ],
      "metadata": {
        "id": "ocWnrIosbiQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][\"chosen_topic_passage\"]"
      ],
      "metadata": {
        "id": "R0XXR0fnbdK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we want to take all the sentences from each \"chosen_topic_passage\" and separately use those as the training data"
      ],
      "metadata": {
        "id": "KdNC7DjkgVhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First Try (not the correct format)"
      ],
      "metadata": {
        "id": "u1BjL1A1jKDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passages = [f\" \".join([f\"{passage}\" for passage in sample['chosen_topic_passage']]) for sample in data]"
      ],
      "metadata": {
        "id": "7fjk-T6ihnVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "8HEK7CQGiRDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data,tokens_only=False):\n",
        "  for i, line in enumerate(data):\n",
        "    tokens = gensim.utils.simple_preprocess(line)\n",
        "    if tokens_only:\n",
        "      yield tokens\n",
        "    else:\n",
        "      # For training data, add tags\n",
        "      yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
      ],
      "metadata": {
        "id": "45Tw-TILgkcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess training data"
      ],
      "metadata": {
        "id": "zafYAVf7hNOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = list(preprocess(passages))"
      ],
      "metadata": {
        "id": "TBgKPi1vhRUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus[0]"
      ],
      "metadata": {
        "id": "BU-EUYAcieNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not what I want -> here I have all sentences together, need to seperate them!"
      ],
      "metadata": {
        "id": "o5_qvkipjBUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Second Try (seems to work as it should)"
      ],
      "metadata": {
        "id": "2md2VQPCjMW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passages = [[passage for passage in sample['chosen_topic_passage']] for sample in data]"
      ],
      "metadata": {
        "id": "MDF-fjxFjMIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "n6FE288HlY54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0][0]"
      ],
      "metadata": {
        "id": "SxFtjAWnlXWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a nested list of lists -> let's unfold that list in a way that the nested entries of those lists are their own entries"
      ],
      "metadata": {
        "id": "05A7PUP-lIID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for i in passages:\n",
        "  for entry in i:\n",
        "    sentences.append(entry)\n",
        "    \n",
        "sentences[1]"
      ],
      "metadata": {
        "id": "gd0zQIcblSq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function for preprocessing our data"
      ],
      "metadata": {
        "id": "n2_Oo8r-mqPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data,tokens_only=False):\n",
        "  for i, line in enumerate(data):\n",
        "    tokens = gensim.utils.simple_preprocess(line)\n",
        "    if tokens_only:\n",
        "      yield tokens\n",
        "    else:\n",
        "      # For training data, add tags\n",
        "      yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
      ],
      "metadata": {
        "id": "-iA2cPQqmybo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess training data"
      ],
      "metadata": {
        "id": "RtdD5vcSm4Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = list(preprocess(sentences))"
      ],
      "metadata": {
        "id": "YjEVPsKXm6A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus[0]"
      ],
      "metadata": {
        "id": "XVByhcJVnKsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-based chatbots\n",
        "\n",
        "This approach is more or less the same as showed during Tutorial_08."
      ],
      "metadata": {
        "id": "WvzjGvo6kcDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data extraction"
      ],
      "metadata": {
        "id": "7pC5ExS4kl4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('train.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    data = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(data))"
      ],
      "metadata": {
        "id": "Il9HbCo5kpEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just for looking at the raw dataset\n",
        "data[0]"
      ],
      "metadata": {
        "id": "pK0ZNZ7-k4n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataframe is never used, but it is useful for looking at the dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "OdxOc1DAk5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do some data extraction from the dataset. We want to produce a set were we have the dialog with a apprentice and wizard, these are then used to fine train the model. \n",
        "\n",
        "This limits the model, as it won't have any \"memory\"/context from the complete conversation. But the aim is for it to be acting as a \"smart vector-database\" and retrive similar enough passages. "
      ],
      "metadata": {
        "id": "nbuc0IvTk7gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = []\n",
        "wizard_responses = []\n",
        "\n",
        "chosen_topic = \"\"\n",
        "\n",
        "for dialogue in data:\n",
        "\n",
        "  if not 'Wizard' in dialogue['dialog'][0]['speaker']:\n",
        "      continue\n",
        "\n",
        "  chosen_topic = dialogue['chosen_topic']\n",
        "\n",
        "  user_query.append(chosen_topic + \" \" + dialogue['persona'])\n",
        "\n",
        "  for i, prompt in enumerate(dialogue['dialog']):\n",
        "\n",
        "    if i % 2 == 0:\n",
        "      wizard_responses.append(chosen_topic + \" \" + prompt['text'])\n",
        "    else:\n",
        "      user_query.append(chosen_topic + \" \" + prompt['text'])\n",
        "\n",
        "data_pairs = []\n",
        "\n",
        "for i, _ in enumerate(wizard_responses):\n",
        "\n",
        "  data_pairs.append(\n",
        "      {'message': user_query[i], 'response': wizard_responses[i]}\n",
        "      )"
      ],
      "metadata": {
        "id": "qQjb9ztbk-Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Now we are able to train the model"
      ],
      "metadata": {
        "id": "s0mJ7boRlEge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sentence_transformers"
      ],
      "metadata": {
        "id": "zAsXycTnlISd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "okUDut2UlI_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings = semb_model.encode([sample['message'] for sample in data_pairs], convert_to_tensor=True, show_progress_bar=True, device='cuda')"
      ],
      "metadata": {
        "id": "KQGs4ILllLUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model usage"
      ],
      "metadata": {
        "id": "yijEGCDnlOvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hnswlib"
      ],
      "metadata": {
        "id": "z1jRF5cZlPve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hnswlib\n",
        "\n",
        "# Create empty index\n",
        "hnswlib_index = hnswlib.Index(space='cosine', dim=corpus_embeddings.size(1))\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = \"./emp_dialogue_hnswlib.index\"\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print(\"Loading index...\")\n",
        "    hnswlib_index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print(\"Start creating HNSWLIB index\")\n",
        "    hnswlib_index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=400, M=64)\n",
        "    #  Compute the HNSWLIB index (it may take a while)\n",
        "    hnswlib_index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(\"Saving index to:\", index_path)\n",
        "    hnswlib_index.save_index(index_path)"
      ],
      "metadata": {
        "id": "OZtXIyKllSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_response(message, mes_resp_pairs, index, re_ranking_model=None, top_k=32):\n",
        "    message_embedding = semb_model.encode(message, convert_to_tensor=True).cpu()\n",
        "\n",
        "    corpus_ids, _ = index.knn_query(message_embedding, k=top_k)\n",
        "\n",
        "    model_inputs = [(message, mes_resp_pairs[idx]['response']) for idx in corpus_ids[0]]\n",
        "    cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "    idx = np.argsort(-cross_scores)[0]\n",
        "\n",
        "    return mes_resp_pairs[corpus_ids[0][idx]]['response']"
      ],
      "metadata": {
        "id": "hflSi3AOlXvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_response = get_response(\n",
        "    \"I'm a huge fan of science fiction myself!\", data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        ")\n",
        "chatbot_response"
      ],
      "metadata": {
        "id": "wqFoiYERlcq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "\n",
        "Testing the model by loading in the **test_random_split.json** file."
      ],
      "metadata": {
        "id": "c4tRo2Aulfe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data extraction\n",
        "\n",
        "Before we can perform the testing, we need to perform some data extraction. The strategy is to find a conversation between a wizard and a apprentice, and use that to test the accuracy/precision of the model.\n",
        "\n",
        "What we expect is that the model produces a responce that is similar to the one that was used in the conversation. Note that this does not satisfy the \"correct passage\" requirement."
      ],
      "metadata": {
        "id": "GoH-vE-hlhz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_random_split.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    test = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(test))"
      ],
      "metadata": {
        "id": "4pidFaVDljuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_extract = []\n",
        "\n",
        "for i, conversation in enumerate(test):\n",
        "\n",
        "  test_extract.append(\"new_conv_\" + str(i))\n",
        "\n",
        "  for j, dialog in enumerate(conversation['dialog']):\n",
        "\n",
        "    if \"Wizard\" in dialog['speaker']:\n",
        "\n",
        "      if j == 0:\n",
        "        continue\n",
        "\n",
        "      test_extract.append({'wizard':dialog['text']})\n",
        "\n",
        "    if \"Apprentice\" in dialog['speaker']:\n",
        "      test_extract.append({'apprentice':dialog['text']})\n",
        "\n",
        "test_extract[:10]"
      ],
      "metadata": {
        "id": "Hq28664DlnHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is still quite \"dirty\". So we will perform the cumbersome clean up in the next cell to get a list of directories, were the directories contians the matches/pairs that will be used for testing."
      ],
      "metadata": {
        "id": "nceQF58olprD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pair = []\n",
        "\n",
        "test_pairs = []\n",
        "\n",
        "for i, text in enumerate(test_extract):\n",
        "\n",
        "  if \"new_conv_\" in text:\n",
        "    continue\n",
        "\n",
        "  pair.append(text)\n",
        "\n",
        "  if len(pair) == 2:\n",
        "    \n",
        "    entry = {'apprentice':\"\", 'wizard': \"\"}\n",
        "\n",
        "    for _, e in enumerate(pair):\n",
        "\n",
        "      if 'apprentice' in e.keys():\n",
        "        entry['apprentice'] = e['apprentice']\n",
        "\n",
        "      if 'wizard' in e.keys():\n",
        "        entry['wizard'] = e['wizard']\n",
        "\n",
        "\n",
        "    test_pairs.append(entry)\n",
        "    pair = []\n",
        "\n",
        "test_pairs[:5]"
      ],
      "metadata": {
        "id": "2Zj0kupJlrg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rand_int = random.randrange(0,500)\n",
        "\n",
        "chatbot_response = get_response(\n",
        "      test_pairs[rand_int]['apprentice'], data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        "  )\n",
        "\n",
        "print(test_pairs[rand_int]['apprentice'])\n",
        "print(test_pairs[rand_int]['wizard'])\n",
        "print(chatbot_response)"
      ],
      "metadata": {
        "id": "d4pVzX4mlwG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should be able to do some testing. Here we use two approaches, a naive one were we are looking at the exact matches, and one were we are doing BLEU-scoring\n",
        "\n",
        "The naive approach is useful for the assignment requirement were it is specified to find the \"correct passage\". \n",
        "\n",
        "The BLEU-score is a score to see how close the precision is. It might not provide that much (if any) useful informaiton to us, as we are not doing a sentence-to-sentence transformation."
      ],
      "metadata": {
        "id": "1dNr1tNVlyI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "correct_responses = 0\n",
        "\n",
        "bleu_scores = []\n",
        "\n",
        "for _, entry in enumerate(test_pairs):\n",
        "  chatbot_response = get_response(\n",
        "      entry['apprentice'], data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        "  )\n",
        "\n",
        "  # Naive accuracy\n",
        "  if chatbot_response == entry['wizard']:\n",
        "    correct_responses += 1\n",
        "  \n",
        "  # BLEU score calculation\n",
        "\n",
        "  reference = [entry['apprentice'].split()]\n",
        "  candidate = chatbot_response.split()\n",
        "  bleu_scores.append(sentence_bleu(reference, candidate))\n",
        "\n",
        "accuracy = correct_responses / len(test_pairs)\n",
        "\n",
        "print(\"Test accuracy (%):\", accuracy * 100)\n",
        "print(\"Average BLEU-score:\", sum(bleu_scores) / len(bleu_scores))"
      ],
      "metadata": {
        "id": "VKXACty1l1gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-based response chatbot (Not accurate title)\n",
        "\n",
        "This implementation aims to create a retrieval-based responce chatbot to provide the correct awnser to a given passage. This is done by taking all the correct awnsers, generating embeddings with them and then performing a \"search\" in the created vector space to find the passage that has the closest match with the given passage"
      ],
      "metadata": {
        "id": "4du53hLC0l4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data extraction\n",
        "\n",
        "Extracts user prompts and wizard responses from a list of dialogues and stores them in separate lists based on the condition that the dialogue speaker is the wizard and the order in which they appear in the dialogue.\n",
        "\n",
        "Here we also concatenate the strings with some extra information, like the chosen topic, in order to increase the precision of the search later. This is a valid approach and can be seen as that we are just adding more context to the passage."
      ],
      "metadata": {
        "id": "9PVaSxgh1ZYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sets of documents\n",
        "user_query = []\n",
        "wizard_responses = []\n",
        "\n",
        "chosen_topic = \"\"\n",
        "\n",
        "for dialogue in data:\n",
        "\n",
        "  if not 'Wizard' in dialogue['dialog'][0]['speaker']:\n",
        "      continue\n",
        "\n",
        "  chosen_topic = dialogue['chosen_topic']\n",
        "\n",
        "  user_query.append(chosen_topic + \" \" + dialogue['persona'])\n",
        "\n",
        "  for i, prompt in enumerate(dialogue['dialog']):\n",
        "\n",
        "    if i % 2 == 0:\n",
        "      wizard_responses.append(chosen_topic + \" \" + prompt['text'])\n",
        "    else:\n",
        "      user_query.append(chosen_topic + \" \" + prompt['text'])"
      ],
      "metadata": {
        "id": "de0vqxyN1UYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document vectorization"
      ],
      "metadata": {
        "id": "83DNodJY1ee8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer \n",
        "# CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
      ],
      "metadata": {
        "id": "gzjURoxn1h1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the vectorizer object\n",
        "#countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words= 'english')"
      ],
      "metadata": {
        "id": "_iySfXyq1l-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert th documents into a matrix\n",
        "#count_wm = countvectorizer.fit_transform(train)\n",
        "query_wm = tfidfvectorizer.fit_transform(user_query)\n",
        "response_wm = tfidfvectorizer.fit_transform(wizard_responses)"
      ],
      "metadata": {
        "id": "epLmOjK31n_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the terms found in the corpora\n",
        "# if we take same parameters on both Classes(CountVectorizer and TfidfVectorizer) , it will give same output of get_feature_names() methods)\n",
        "query_tokens = tfidfvectorizer.get_feature_names_out(query_wm)\n",
        "responce_tokens = tfidfvectorizer.get_feature_names_out(response_wm)"
      ],
      "metadata": {
        "id": "hgDz7AHK1p8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification\n",
        "\n",
        "Some output in order to quickly verify the embeddings"
      ],
      "metadata": {
        "id": "lfh0J_oE2F4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "responce_vectors = tfidfvectorizer.transform(wizard_responses)\n",
        "query_vectors = tfidfvectorizer.transform(user_query)\n",
        "\n",
        "print('responce_vectors:\\n', responce_vectors)\n",
        "\n",
        "print('query_vectors:\\n', query_vectors)"
      ],
      "metadata": {
        "id": "5AZ_br6Z1sgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([(query_tokens[j], query_vectors[0, j]) for j in query_vectors[0].nonzero()[1]], key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "ue_REmXm1vqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search the vector space\n",
        "\n",
        "Here we calculate the closest neighbor to the embedding of the query, and hopefully that is the \"correct\" passage we are looking for."
      ],
      "metadata": {
        "id": "3hkFx9601yvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "query = 'Gardening: i like to garden.'\n",
        "\n",
        "query_vec = tfidfvectorizer.transform([query])[0]\n",
        "\n",
        "index = np.argmax([query_vec.multiply(vector_documents[i]).sum() for i in range(len(train))])\n",
        "print(train[index])"
      ],
      "metadata": {
        "id": "MP-6PIKB1yFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKDHFfuM1vgx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}