{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamzki99/nlp-zlatan/blob/feature%2Fclustering_verification/nlp_zlatan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive"
      ],
      "metadata": {
        "id": "1LcgYJ860QY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSvTgIasmNY",
        "outputId": "b776babb-eb91-4f9e-c95c-43f1624cdbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nlp-datasets/wizard_of_wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asHbxFDYtSbT",
        "outputId": "708bf2fa-f487-4c21-ad69-203532e38c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp-datasets/wizard_of_wikipedia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-based chatbots\n",
        "\n",
        "This approach is more or less the same as showed during Tutorial_08."
      ],
      "metadata": {
        "id": "WvzjGvo6kcDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data extraction"
      ],
      "metadata": {
        "id": "7pC5ExS4kl4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('train.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    data = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(data))"
      ],
      "metadata": {
        "id": "Il9HbCo5kpEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just for looking at the raw dataset\n",
        "data[0]"
      ],
      "metadata": {
        "id": "pK0ZNZ7-k4n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataframe is never used, but it is useful for looking at the dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "OdxOc1DAk5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do some data extraction from the dataset. We want to produce a set were we have the dialog with a apprentice and wizard, these are then used to fine train the model. \n",
        "\n",
        "This limits the model, as it won't have any \"memory\"/context from the complete conversation. But the aim is for it to be acting as a \"smart vector-database\" and retrive similar enough passages. "
      ],
      "metadata": {
        "id": "nbuc0IvTk7gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = []\n",
        "wizard_responses = []\n",
        "\n",
        "chosen_topic = \"\"\n",
        "\n",
        "for dialogue in data:\n",
        "\n",
        "  if not 'Wizard' in dialogue['dialog'][0]['speaker']:\n",
        "      continue\n",
        "\n",
        "  chosen_topic = dialogue['chosen_topic']\n",
        "\n",
        "  user_query.append(chosen_topic + \" \" + dialogue['persona'])\n",
        "\n",
        "  for i, prompt in enumerate(dialogue['dialog']):\n",
        "\n",
        "    if i % 2 == 0:\n",
        "      wizard_responses.append(chosen_topic + \" \" + prompt['text'])\n",
        "    else:\n",
        "      user_query.append(chosen_topic + \" \" + prompt['text'])\n",
        "\n",
        "data_pairs = []\n",
        "\n",
        "for i, _ in enumerate(wizard_responses):\n",
        "\n",
        "  data_pairs.append(\n",
        "      {'message': user_query[i], 'response': wizard_responses[i]}\n",
        "      )"
      ],
      "metadata": {
        "id": "qQjb9ztbk-Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Now we are able to train the model"
      ],
      "metadata": {
        "id": "s0mJ7boRlEge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sentence_transformers"
      ],
      "metadata": {
        "id": "zAsXycTnlISd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "okUDut2UlI_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings = semb_model.encode([sample['message'] for sample in data_pairs], convert_to_tensor=True, show_progress_bar=True, device='cuda')"
      ],
      "metadata": {
        "id": "KQGs4ILllLUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model usage"
      ],
      "metadata": {
        "id": "yijEGCDnlOvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hnswlib"
      ],
      "metadata": {
        "id": "z1jRF5cZlPve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hnswlib\n",
        "\n",
        "# Create empty index\n",
        "hnswlib_index = hnswlib.Index(space='cosine', dim=corpus_embeddings.size(1))\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = \"./emp_dialogue_hnswlib.index\"\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print(\"Loading index...\")\n",
        "    hnswlib_index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print(\"Start creating HNSWLIB index\")\n",
        "    hnswlib_index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=400, M=64)\n",
        "    #  Compute the HNSWLIB index (it may take a while)\n",
        "    hnswlib_index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(\"Saving index to:\", index_path)\n",
        "    hnswlib_index.save_index(index_path)"
      ],
      "metadata": {
        "id": "OZtXIyKllSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_response(message, mes_resp_pairs, index, re_ranking_model=None, top_k=32):\n",
        "    message_embedding = semb_model.encode(message, convert_to_tensor=True).cpu()\n",
        "\n",
        "    corpus_ids, _ = index.knn_query(message_embedding, k=top_k)\n",
        "\n",
        "    model_inputs = [(message, mes_resp_pairs[idx]['response']) for idx in corpus_ids[0]]\n",
        "    cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "    idx = np.argsort(-cross_scores)[0]\n",
        "\n",
        "    return mes_resp_pairs[corpus_ids[0][idx]]['response']"
      ],
      "metadata": {
        "id": "hflSi3AOlXvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_response = get_response(\n",
        "    \"I'm a huge fan of science fiction myself!\", data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        ")\n",
        "chatbot_response"
      ],
      "metadata": {
        "id": "wqFoiYERlcq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "\n",
        "Testing the model by loading in the **test_random_split.json** file."
      ],
      "metadata": {
        "id": "c4tRo2Aulfe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data extraction\n",
        "\n",
        "Before we can perform the testing, we need to perform some data extraction. The strategy is to find a conversation between a wizard and a apprentice, and use that to test the accuracy/precision of the model.\n",
        "\n",
        "What we expect is that the model produces a responce that is similar to the one that was used in the conversation. Note that this does not satisfy the \"correct passage\" requirement."
      ],
      "metadata": {
        "id": "GoH-vE-hlhz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_random_split.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    test = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(test))"
      ],
      "metadata": {
        "id": "4pidFaVDljuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_extract = []\n",
        "\n",
        "for i, conversation in enumerate(test):\n",
        "\n",
        "  test_extract.append(\"new_conv_\" + str(i))\n",
        "\n",
        "  for j, dialog in enumerate(conversation['dialog']):\n",
        "\n",
        "    if \"Wizard\" in dialog['speaker']:\n",
        "\n",
        "      if j == 0:\n",
        "        continue\n",
        "\n",
        "      test_extract.append({'wizard':dialog['text']})\n",
        "\n",
        "    if \"Apprentice\" in dialog['speaker']:\n",
        "      test_extract.append({'apprentice':dialog['text']})\n",
        "\n",
        "test_extract[:10]"
      ],
      "metadata": {
        "id": "Hq28664DlnHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is still quite \"dirty\". So we will perform the cumbersome clean up in the next cell to get a list of directories, were the directories contians the matches/pairs that will be used for testing."
      ],
      "metadata": {
        "id": "nceQF58olprD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pair = []\n",
        "\n",
        "test_pairs = []\n",
        "\n",
        "for i, text in enumerate(test_extract):\n",
        "\n",
        "  if \"new_conv_\" in text:\n",
        "    continue\n",
        "\n",
        "  pair.append(text)\n",
        "\n",
        "  if len(pair) == 2:\n",
        "    \n",
        "    entry = {'apprentice':\"\", 'wizard': \"\"}\n",
        "\n",
        "    for _, e in enumerate(pair):\n",
        "\n",
        "      if 'apprentice' in e.keys():\n",
        "        entry['apprentice'] = e['apprentice']\n",
        "\n",
        "      if 'wizard' in e.keys():\n",
        "        entry['wizard'] = e['wizard']\n",
        "\n",
        "\n",
        "    test_pairs.append(entry)\n",
        "    pair = []\n",
        "\n",
        "test_pairs[:5]"
      ],
      "metadata": {
        "id": "2Zj0kupJlrg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rand_int = random.randrange(0,500)\n",
        "\n",
        "chatbot_response = get_response(\n",
        "      test_pairs[rand_int]['apprentice'], data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        "  )\n",
        "\n",
        "print(test_pairs[rand_int]['apprentice'])\n",
        "print(test_pairs[rand_int]['wizard'])\n",
        "print(chatbot_response)"
      ],
      "metadata": {
        "id": "d4pVzX4mlwG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should be able to do some testing. Here we use two approaches, a naive one were we are looking at the exact matches, and one were we are doing BLEU-scoring\n",
        "\n",
        "The naive approach is useful for the assignment requirement were it is specified to find the \"correct passage\". \n",
        "\n",
        "The BLEU-score is a score to see how close the precision is. It might not provide that much (if any) useful informaiton to us, as we are not doing a sentence-to-sentence transformation."
      ],
      "metadata": {
        "id": "1dNr1tNVlyI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "correct_responses = 0\n",
        "\n",
        "bleu_scores = []\n",
        "\n",
        "for _, entry in enumerate(test_pairs):\n",
        "  chatbot_response = get_response(\n",
        "      entry['apprentice'], data_pairs, hnswlib_index, re_ranking_model=xenc_model\n",
        "  )\n",
        "\n",
        "  # Naive accuracy\n",
        "  if chatbot_response == entry['wizard']:\n",
        "    correct_responses += 1\n",
        "  \n",
        "  # BLEU score calculation\n",
        "\n",
        "  reference = [entry['apprentice'].split()]\n",
        "  candidate = chatbot_response.split()\n",
        "  bleu_scores.append(sentence_bleu(reference, candidate))\n",
        "\n",
        "accuracy = correct_responses / len(test_pairs)\n",
        "\n",
        "print(\"Test accuracy (%):\", accuracy * 100)\n",
        "print(\"Average BLEU-score:\", sum(bleu_scores) / len(bleu_scores))"
      ],
      "metadata": {
        "id": "VKXACty1l1gM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}