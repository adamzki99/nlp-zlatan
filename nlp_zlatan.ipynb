{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamzki99/nlp-zlatan/blob/all-MiniLM-L6-v2-implementation/nlp_zlatan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive"
      ],
      "metadata": {
        "id": "1LcgYJ860QY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSvTgIasmNY",
        "outputId": "b776babb-eb91-4f9e-c95c-43f1624cdbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nlp-datasets/wizard_of_wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asHbxFDYtSbT",
        "outputId": "708bf2fa-f487-4c21-ad69-203532e38c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp-datasets/wizard_of_wikipedia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# all-MiniLM-L6-v2\n",
        "\n",
        "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 "
      ],
      "metadata": {
        "id": "vfO3cP1f1oq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('valid_random_split.json', 'r') as file:\n",
        "    json_data = file.read()\n",
        "    data = json.loads(json_data)\n",
        "\n",
        "print('Datatype:', type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDLs33Df1uzX",
        "outputId": "ed57cc26-291b-4828-c46f-fe71afc7859d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_extract = []\n",
        "\n",
        "for i, conversation in enumerate(data):\n",
        "\n",
        "  data_extract.append(\"new_conv_\" + str(i))\n",
        "\n",
        "  for j, dialog in enumerate(conversation['dialog']):\n",
        "\n",
        "    if \"Wizard\" in dialog['speaker']:\n",
        "\n",
        "      if j == 0:\n",
        "        continue\n",
        "\n",
        "      data_extract.append({'wizard':dialog['text']})\n",
        "\n",
        "    if \"Apprentice\" in dialog['speaker']:\n",
        "      data_extract.append({'apprentice':dialog['text']})\n",
        "\n",
        "data_extract[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88GhV8Vf13v-",
        "outputId": "56d0da65-4a95-4d11-e351-40fe1f9c7d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['new_conv_0',\n",
              " {'apprentice': \"I like Gardening, even when I've only been doing it for a short time.\"},\n",
              " {'wizard': 'I live on a farm, we garden all year long, it is very relaxing.'},\n",
              " {'apprentice': \"That sounds great.  I've always thought that I would love living in a farm, but I;ve always lived in the city.  What do you mostly plant?\"},\n",
              " {'wizard': 'I have planted several fruits trees, tomatoes, jalepenos, bell peppers, onions, Garlic, and potatoes mostly.'},\n",
              " {'apprentice': 'Great, I love the idea of growing my own vegetables and fruits! Do you have animals in the farm?'},\n",
              " {'wizard': 'yes i do. Cows, chickens, Micro pigs, Guinneas, We also do forest growing also. we plants large pine trees.'},\n",
              " {'apprentice': 'Wow, it sounds amazing, the Micro-pigs are so cute! are they trainable to be well behaved?'},\n",
              " {'wizard': 'yes they are. they are extremely smart. most people buy them for inside pets. you can train the to use a litter box just like a cat. When families started using vines and trees to build their houses out of there was several species of trees and vines that were eliminated by them.'},\n",
              " {'apprentice': 'Great, I enjoyed our chat.  Great luck with the farm! Maybe I will get a Micro-pig someday.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair = []\n",
        "conversation_pairs = []\n",
        "\n",
        "for i, text in enumerate(data_extract):\n",
        "\n",
        "  if \"new_conv_\" in text:\n",
        "    continue\n",
        "\n",
        "  pair.append(text)\n",
        "\n",
        "  if len(pair) == 2:\n",
        "    \n",
        "    entry = {'apprentice':\"\", 'wizard': \"\"}\n",
        "\n",
        "    for _, e in enumerate(pair):\n",
        "\n",
        "      if 'apprentice' in e.keys():\n",
        "        entry['apprentice'] = e['apprentice']\n",
        "\n",
        "      if 'wizard' in e.keys():\n",
        "        entry['wizard'] = e['wizard']\n",
        "\n",
        "\n",
        "    conversation_pairs.append(entry)\n",
        "    pair = []\n",
        "\n",
        "conversation_pairs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ZXs_rd3T2A",
        "outputId": "f47d64a9-6246-424a-a000-5d970d7e3ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'apprentice': \"I like Gardening, even when I've only been doing it for a short time.\",\n",
              "  'wizard': 'I live on a farm, we garden all year long, it is very relaxing.'},\n",
              " {'apprentice': \"That sounds great.  I've always thought that I would love living in a farm, but I;ve always lived in the city.  What do you mostly plant?\",\n",
              "  'wizard': 'I have planted several fruits trees, tomatoes, jalepenos, bell peppers, onions, Garlic, and potatoes mostly.'},\n",
              " {'apprentice': 'Great, I love the idea of growing my own vegetables and fruits! Do you have animals in the farm?',\n",
              "  'wizard': 'yes i do. Cows, chickens, Micro pigs, Guinneas, We also do forest growing also. we plants large pine trees.'},\n",
              " {'apprentice': 'Wow, it sounds amazing, the Micro-pigs are so cute! are they trainable to be well behaved?',\n",
              "  'wizard': 'yes they are. they are extremely smart. most people buy them for inside pets. you can train the to use a litter box just like a cat. When families started using vines and trees to build their houses out of there was several species of trees and vines that were eliminated by them.'},\n",
              " {'apprentice': 'I would like to know more about bob ross', 'wizard': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeWwKIol34Dw",
        "outputId": "426b089c-60fa-4f95-a73d-693441b79daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "81db8700cbf34ecd8a50482451b2c3f4",
            "cbef810e88054b31b43f9f8e1939afb2",
            "2e34b8b3cb63481fa4414cd42621af0d",
            "d0278cfd017840c3be66f23be675156d",
            "8842624f1d6a4a25825b3331e47edac7",
            "9dd8e460beea4a01afdf48e67b4ed385",
            "c1676e92044e42f3861f4659f9578129",
            "42a8e682a64f49f6879572cb6a5361f8",
            "726b5496b83d4dc8ba66f21ede668f3b",
            "1a5e42eeb100481d80f763b611809f7a",
            "dc0fb36be8644960913d205fbcc6ed48",
            "608976f717384b5496433e5f565d4837",
            "fd2ce5d810ba45d8a1ef8f21d1c72f3c",
            "0c84c92380764714bdcf7c13dce3c874",
            "d3e624e5a58742fd84ecdb8d6fc2499f",
            "3b97cae306184002907d06cb7f7747b7",
            "84385acbd72b42319424d4e85236b95a",
            "4901f5aac2cf4da4889e906c7f14272f",
            "9ee39d2dc7624d949fbf78d282270617",
            "e8d8b6354cf34814ae3d9285291508fd",
            "4ba1823ae01c41f1b89ee7dfa4f23298",
            "00c1436aacd64e748327bdf235742190",
            "68ac5759eb324ef880c2d2436b7d22bd",
            "68758c8bf35745d0b384b0c2082e7099",
            "6ac2e26d98b746a889216848c53876de",
            "452ff869943a4abe8ba79189088c4a84",
            "4fea106954dd475c9099944cd6b5d5a9",
            "28160355763948189213abf46c54b48a",
            "aa3734725e7b42bea7ac32506238b54e",
            "b797af471d7a41909e672577a7dec4b4",
            "37075f98e0234c98863d2549864bb4db",
            "8dc512eb68c24c48ae35ca7455169b74",
            "e9c9e596b32c4af899f1afae0a48eca8",
            "4de68312c8db474da7291704b3dff940",
            "543ce15f2f55428886950f4bee32db8d",
            "5a25deb5ec8b4719bbee0d088af22e89",
            "90388b6fc92246849bbc3d3877b613f1",
            "2ded95ea61a04f04b714bf4c432b06a2",
            "292557092518410c996464231bd54a60",
            "e42892745f464690bd39c148c45b7eef",
            "7a79c88eb07d43129549ee4e435f6843",
            "2689f237f9524ed79dc9761dacd78954",
            "abd6c770e87944fc9f5d11c827710936",
            "95b3f6680d19476da293a3236b171351",
            "4f6cd60698a344289268ce0ce168dc30",
            "52382556c3a24fb9b1630db99c48360e",
            "5782742aa6084fbb82146cc29585db85",
            "1c16de0ed2bb493f892e67077547709e",
            "80253941984448f0a11c1ab2243cf7c8",
            "796553830ceb4fd2b44d9cd12cad77b7",
            "18c7a95f0f7d49e2ae32f404be1d7e19",
            "8885b49fd123498eaedb2437765c7754",
            "3b240ab2d99b45f091005f2a62b9b318",
            "f69ab1810ffa4c98841ebc65a16c8c40",
            "bf5f7a10e61a4adcadcd1c76ddcc0c8b",
            "1f9c145773bd48fb858824fe1cea55d5",
            "36241d3ba4a64908a0cc3f229435ecaf",
            "e93d907333284e55bb5add595822d2bf",
            "e59fb85a99fb4b1a9c41abbf681e24a8",
            "38ec9310411f42419bb602791f289bbc",
            "3fd392027ca8486d8655a0974ee49a32",
            "c74b36a01b2249edb0263493b47a040c",
            "da9ffb94aa814351a836ba3bf5acb3bd",
            "3d8c97afd2af44b99424005badd3db46",
            "510ade0a191143ef9abd9ab6beb09b87",
            "ffc9175a5c8c4568800ea59f28795000"
          ]
        },
        "id": "Gyqb2E2I3x2E",
        "outputId": "a6d4b736-10fe-4089-a09c-f75dddfaeef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81db8700cbf34ecd8a50482451b2c3f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "608976f717384b5496433e5f565d4837"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68ac5759eb324ef880c2d2436b7d22bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4de68312c8db474da7291704b3dff940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f6cd60698a344289268ce0ce168dc30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f9c145773bd48fb858824fe1cea55d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "\n",
        "for i, pair in enumerate(conversation_pairs[:1000]):\n",
        "\n",
        "  sentences.append([pair['apprentice'], pair['wizard']])\n",
        "\n",
        "\n",
        "# Tokenize sentences\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "VxjuxEyr4OiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSJI1JJP7RoO",
        "outputId": "34c9e3bb-f85e-4a97-e208-22ede67347db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute token embeddings\n",
        "model.to(device)\n",
        "encoded_input.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "cax5KWNh5Cv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using mean-pooling\n",
        "\n",
        "We are using mean-pooling to aggregate the sentence embeddings into a vector representation that aims to capture the meaning of the sentence. This is performed by averaging the embeddings dimensions.\n",
        "\n",
        "By also applying the attention mask wich is provided with the model, we are able improve the **accuracy** of the averaging. This is becase the function wont be taking into acount the words that wont provide usefull information, e.g. stop-words."
      ],
      "metadata": {
        "id": "URC3cNWGedJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ],
      "metadata": {
        "id": "x9azfyoj84PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform pooling\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "# Normalize embeddings\n",
        "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)"
      ],
      "metadata": {
        "id": "txEaeBia89kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u1tCMbf5UBd",
        "outputId": "99dd6fcd-4d67-4179-fc45-23372ad4255d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.22.4)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2119666 sha256=a85d5ce17216427f749305835d865837d0de12b50ed9a01c5248d9f3cc05f187\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hnswlib\n",
        "\n",
        "# Create the HNSW index\n",
        "index = hnswlib.Index(space='l2', dim=sentence_embeddings.shape[1])\n",
        "index.init_index(max_elements=len(sentence_embeddings), ef_construction=200, M=16)\n",
        "\n",
        "# Add sentence embeddings to the index\n",
        "index.add_items(sentence_embeddings.cpu().numpy())"
      ],
      "metadata": {
        "id": "yRxSbw3A8LbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = []\n",
        "message.append(\"I like Gardening, even when I've only been doing it for a short time.\")\n",
        "\n",
        "encoded_message = tokenizer(message, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "encoded_message.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model_output_message = model(**encoded_message)\n",
        "\n",
        "# Perform pooling\n",
        "query_embedding = mean_pooling(model_output_message, encoded_message['attention_mask'])\n",
        "\n",
        "# Normalize embedding\n",
        "#query_embedding = F.normalize(model_output_message, p=2, dim=1)\n",
        "\n",
        "# Perform a similarity search\n",
        "k = 5  # Number of closest neighbors to retrieve\n",
        "labels, distances = index.knn_query(query_embedding.cpu(), k=k)"
      ],
      "metadata": {
        "id": "4R3ikzESBP2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, indexes in enumerate(labels):\n",
        "  for i, ind in enumerate(indexes):\n",
        "    print(sentences[ind][1], \".\\t Distance:\", distances[0][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1IkFb_GDc4s",
        "outputId": "429ad6f3-c78c-4809-89de-448410b643b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I live on a farm, we garden all year long, it is very relaxing. .\t Distance: 8.451955\n",
            "That's cool I grow sunflowers, oranges, lemons, aloe, a bunch other plants. I find gardening to be relaxing, do you? .\t Distance: 10.845751\n",
            "I prefer to go to the beach and search for rocks that have been washed with sand to form little pebbles. .\t Distance: 11.277561\n",
            "I bet gardening is exhausting definitely not something easy definitely a learning experience. .\t Distance: 11.392678\n",
            "I have planted several fruits trees, tomatoes, jalepenos, bell peppers, onions, Garlic, and potatoes mostly. .\t Distance: 11.965621\n"
          ]
        }
      ]
    }
  ]
}